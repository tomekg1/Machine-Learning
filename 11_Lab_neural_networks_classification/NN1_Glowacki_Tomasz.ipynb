{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "training_set, test_set = mnist.load_data()\n",
    "X_train, y_train = training_set\n",
    "X_test, y_test = test_set\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Dla obrazow w skali szarosci tensorflow przyjmuje dodatkowy wymiar na końcu - liczba kanałów, w RGB jest to 3, a w skali szarości 1\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skalowanie pikseli na zakres 0.0 - 1.0, obraz jest w skali szarości, gdzie wartość pikseli jest reprezentowana na ośmiu bitach\n",
    "X_train = X_train.astype(np.float) / 255.0  \n",
    "X_test = X_test.astype(np.float) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "batch_size = 128\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            keras.layers.Flatten(),\n",
    "            layers.Dense(num_classes, activation=\"softmax\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "375/375 [==============================] - 3s 5ms/step - loss: 15.4697 - accuracy: 0.7848 - val_loss: 6.0739 - val_accuracy: 0.8717\n",
      "Epoch 2/30\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 5.4593 - accuracy: 0.8715 - val_loss: 4.5783 - val_accuracy: 0.8852\n",
      "Epoch 3/30\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 4.2866 - accuracy: 0.8809 - val_loss: 3.9953 - val_accuracy: 0.8904\n",
      "Epoch 4/30\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 3.7718 - accuracy: 0.8833 - val_loss: 3.5099 - val_accuracy: 0.8978\n",
      "Epoch 5/30\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 3.4633 - accuracy: 0.8854 - val_loss: 3.4653 - val_accuracy: 0.8972\n",
      "Epoch 6/30\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 3.1164 - accuracy: 0.8884 - val_loss: 2.9478 - val_accuracy: 0.8967\n",
      "Epoch 7/30\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.9591 - accuracy: 0.8893 - val_loss: 3.0511 - val_accuracy: 0.8910\n",
      "Epoch 8/30\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.8430 - accuracy: 0.8884 - val_loss: 3.5195 - val_accuracy: 0.8759\n",
      "Epoch 9/30\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.8206 - accuracy: 0.8918 - val_loss: 2.9364 - val_accuracy: 0.8936\n",
      "Epoch 10/30\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.7122 - accuracy: 0.8905 - val_loss: 3.0286 - val_accuracy: 0.8988\n",
      "Epoch 11/30\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.6013 - accuracy: 0.8930 - val_loss: 2.9564 - val_accuracy: 0.8897\n",
      "Epoch 12/30\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.5427 - accuracy: 0.8946 - val_loss: 2.8403 - val_accuracy: 0.8933\n",
      "Epoch 13/30\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.4906 - accuracy: 0.8932 - val_loss: 3.4684 - val_accuracy: 0.8792\n",
      "Epoch 14/30\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.5047 - accuracy: 0.8942 - val_loss: 3.0606 - val_accuracy: 0.8896\n",
      "Epoch 15/30\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.4831 - accuracy: 0.8960 - val_loss: 2.9029 - val_accuracy: 0.8862\n",
      "Epoch 16/30\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.5076 - accuracy: 0.8923 - val_loss: 3.1208 - val_accuracy: 0.8748\n",
      "Epoch 17/30\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.4135 - accuracy: 0.8944 - val_loss: 3.2338 - val_accuracy: 0.8777\n",
      "Epoch 18/30\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.4171 - accuracy: 0.8944 - val_loss: 2.7351 - val_accuracy: 0.8976\n",
      "Epoch 19/30\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.4259 - accuracy: 0.8930 - val_loss: 4.0584 - val_accuracy: 0.8600\n",
      "Epoch 20/30\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.4513 - accuracy: 0.8942 - val_loss: 3.2285 - val_accuracy: 0.8880\n",
      "Epoch 21/30\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3619 - accuracy: 0.8963 - val_loss: 2.6624 - val_accuracy: 0.8992\n",
      "Epoch 22/30\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3496 - accuracy: 0.8960 - val_loss: 2.9547 - val_accuracy: 0.8838\n",
      "Epoch 23/30\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.6198 - accuracy: 0.8925 - val_loss: 2.8592 - val_accuracy: 0.9000\n",
      "Epoch 24/30\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3935 - accuracy: 0.8964 - val_loss: 2.7955 - val_accuracy: 0.9000\n",
      "Epoch 25/30\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3375 - accuracy: 0.8952 - val_loss: 3.3718 - val_accuracy: 0.8745\n",
      "Epoch 26/30\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3429 - accuracy: 0.8968 - val_loss: 2.8089 - val_accuracy: 0.8920\n",
      "Epoch 27/30\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2596 - accuracy: 0.8970 - val_loss: 2.5750 - val_accuracy: 0.9016\n",
      "Epoch 28/30\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3594 - accuracy: 0.8955 - val_loss: 3.1261 - val_accuracy: 0.8894\n",
      "Epoch 29/30\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3763 - accuracy: 0.8954 - val_loss: 2.9972 - val_accuracy: 0.8944\n",
      "Epoch 30/30\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3538 - accuracy: 0.8961 - val_loss: 3.6226 - val_accuracy: 0.8745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26aaacc4d90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       980\n",
      "           1       0.92      0.98      0.95      1135\n",
      "           2       0.84      0.88      0.86      1032\n",
      "           3       0.96      0.57      0.72      1010\n",
      "           4       0.96      0.84      0.89       982\n",
      "           5       0.69      0.90      0.78       892\n",
      "           6       0.90      0.94      0.92       958\n",
      "           7       0.84      0.94      0.89      1028\n",
      "           8       0.86      0.84      0.85       974\n",
      "           9       0.87      0.87      0.87      1009\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.88      0.87      0.87     10000\n",
      "weighted avg       0.88      0.87      0.87     10000\n",
      "\n",
      "[[ 943    0    1    1    0   11   13    4    7    0]\n",
      " [   0 1108   15    0    0    1    3    2    5    1]\n",
      " [   6   27  908    1    8   12   20   27   18    5]\n",
      " [   6   19   76  579    3  240    6   37   30   14]\n",
      " [   3    2   18    1  822    2   23   10   22   79]\n",
      " [   7    5    4    5    2  804   23   11   25    6]\n",
      " [   6    1   23    1    5   20  897    1    4    0]\n",
      " [   2    6   23    3    1    1    0  968    4   20]\n",
      " [   4   31   13    6    6   61   14   20  815    4]\n",
      " [   5    5    0    4    8   18    1   77   18  873]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_probab = model.predict(X_test)\n",
    "y_pred = np.argmax(y_probab, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59,850\n",
      "Trainable params: 59,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            keras.layers.Flatten(),\n",
    "            layers.Dense(64, activation=\"tanh\"),\n",
    "            layers.Dense(128, activation=\"tanh\"),\n",
    "            layers.Dense(num_classes, activation=\"softmax\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "375/375 [==============================] - 5s 7ms/step - loss: 0.7270 - accuracy: 0.7735 - val_loss: 0.4526 - val_accuracy: 0.8636\n",
      "Epoch 2/30\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4669 - accuracy: 0.8571 - val_loss: 0.4160 - val_accuracy: 0.8686\n",
      "Epoch 3/30\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4154 - accuracy: 0.8710 - val_loss: 0.3760 - val_accuracy: 0.8892\n",
      "Epoch 4/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3862 - accuracy: 0.8810 - val_loss: 0.3585 - val_accuracy: 0.8907\n",
      "Epoch 5/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3696 - accuracy: 0.8845 - val_loss: 0.3536 - val_accuracy: 0.8861\n",
      "Epoch 6/30\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3598 - accuracy: 0.8884 - val_loss: 0.3448 - val_accuracy: 0.8938\n",
      "Epoch 7/30\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.3341 - accuracy: 0.8950 - val_loss: 0.3266 - val_accuracy: 0.8992\n",
      "Epoch 8/30\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.3151 - accuracy: 0.9022 - val_loss: 0.2821 - val_accuracy: 0.9153\n",
      "Epoch 9/30\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.3042 - accuracy: 0.9058 - val_loss: 0.2893 - val_accuracy: 0.9122\n",
      "Epoch 10/30\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.2951 - accuracy: 0.9078 - val_loss: 0.2792 - val_accuracy: 0.9112\n",
      "Epoch 11/30\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2824 - accuracy: 0.9125 - val_loss: 0.2617 - val_accuracy: 0.9202\n",
      "Epoch 12/30\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2677 - accuracy: 0.9160 - val_loss: 0.2556 - val_accuracy: 0.9210\n",
      "Epoch 13/30\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.2630 - accuracy: 0.9171 - val_loss: 0.2426 - val_accuracy: 0.9248\n",
      "Epoch 14/30\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.2601 - accuracy: 0.9195 - val_loss: 0.2476 - val_accuracy: 0.9201\n",
      "Epoch 15/30\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.2518 - accuracy: 0.9219 - val_loss: 0.2575 - val_accuracy: 0.9194\n",
      "Epoch 16/30\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2568 - accuracy: 0.9198 - val_loss: 0.2423 - val_accuracy: 0.9242\n",
      "Epoch 17/30\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.2450 - accuracy: 0.9230 - val_loss: 0.2446 - val_accuracy: 0.9226\n",
      "Epoch 18/30\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2361 - accuracy: 0.9256 - val_loss: 0.2361 - val_accuracy: 0.9269\n",
      "Epoch 19/30\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.2335 - accuracy: 0.9258 - val_loss: 0.2353 - val_accuracy: 0.9272\n",
      "Epoch 20/30\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.2350 - accuracy: 0.9273 - val_loss: 0.2151 - val_accuracy: 0.9344\n",
      "Epoch 21/30\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.2202 - accuracy: 0.9309 - val_loss: 0.2155 - val_accuracy: 0.9318\n",
      "Epoch 22/30\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.2158 - accuracy: 0.9325 - val_loss: 0.2265 - val_accuracy: 0.9299\n",
      "Epoch 23/30\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.2304 - accuracy: 0.9263 - val_loss: 0.2311 - val_accuracy: 0.9283\n",
      "Epoch 24/30\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.2292 - accuracy: 0.9279 - val_loss: 0.2249 - val_accuracy: 0.9293\n",
      "Epoch 25/30\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.2115 - accuracy: 0.9334 - val_loss: 0.2080 - val_accuracy: 0.9358\n",
      "Epoch 26/30\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2094 - accuracy: 0.9346 - val_loss: 0.2024 - val_accuracy: 0.9410\n",
      "Epoch 27/30\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.2023 - accuracy: 0.9359 - val_loss: 0.2103 - val_accuracy: 0.9348\n",
      "Epoch 28/30\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2087 - accuracy: 0.9341 - val_loss: 0.2090 - val_accuracy: 0.9353\n",
      "Epoch 29/30\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2010 - accuracy: 0.9359 - val_loss: 0.1988 - val_accuracy: 0.9391\n",
      "Epoch 30/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1905 - accuracy: 0.9395 - val_loss: 0.1961 - val_accuracy: 0.9401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26aaad4f430>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.95      0.92      0.93      1032\n",
      "           3       0.91      0.93      0.92      1010\n",
      "           4       0.94      0.93      0.93       982\n",
      "           5       0.89      0.93      0.91       892\n",
      "           6       0.95      0.95      0.95       958\n",
      "           7       0.93      0.94      0.94      1028\n",
      "           8       0.91      0.90      0.90       974\n",
      "           9       0.91      0.89      0.90      1009\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "[[ 957    0    2    1    1    5    7    1    3    3]\n",
      " [   0 1113    2    5    1    3    3    2    6    0]\n",
      " [   9    5  947   19    6    4   10   11   18    3]\n",
      " [   0    1   14  935    1   23    1   13   19    3]\n",
      " [   1    1    2    1  911    2    6    3    3   52]\n",
      " [   3    0    1   25    2  830   12    4   10    5]\n",
      " [  12    3    1    2    7   14  913    1    5    0]\n",
      " [   0    5   19   11    5    1    0  969    5   13]\n",
      " [   6    2   11   28    7   27    9    7  872    5]\n",
      " [   3    5    1    4   30   25    1   31   13  896]]\n"
     ]
    }
   ],
   "source": [
    "y_probab = model.predict(X_test)\n",
    "y_pred = np.argmax(y_probab, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                16010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "375/375 [==============================] - 24s 60ms/step - loss: 1.2451 - accuracy: 0.8357 - val_loss: 0.1017 - val_accuracy: 0.9697\n",
      "Epoch 2/30\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 0.1818 - accuracy: 0.9428 - val_loss: 0.0709 - val_accuracy: 0.9789\n",
      "Epoch 3/30\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 0.1344 - accuracy: 0.9584 - val_loss: 0.0597 - val_accuracy: 0.9808\n",
      "Epoch 4/30\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.1128 - accuracy: 0.9651 - val_loss: 0.0534 - val_accuracy: 0.9832\n",
      "Epoch 5/30\n",
      "375/375 [==============================] - 20s 55ms/step - loss: 0.0989 - accuracy: 0.9694 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
      "Epoch 6/30\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0880 - accuracy: 0.9729 - val_loss: 0.0459 - val_accuracy: 0.9862\n",
      "Epoch 7/30\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0796 - accuracy: 0.9754 - val_loss: 0.0408 - val_accuracy: 0.9872\n",
      "Epoch 8/30\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0739 - accuracy: 0.9773 - val_loss: 0.0451 - val_accuracy: 0.9866\n",
      "Epoch 9/30\n",
      "375/375 [==============================] - 20s 53ms/step - loss: 0.0696 - accuracy: 0.9790 - val_loss: 0.0416 - val_accuracy: 0.9878\n",
      "Epoch 10/30\n",
      "375/375 [==============================] - 20s 52ms/step - loss: 0.0618 - accuracy: 0.9809 - val_loss: 0.0388 - val_accuracy: 0.9892\n",
      "Epoch 11/30\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.0607 - accuracy: 0.9804 - val_loss: 0.0394 - val_accuracy: 0.9883\n",
      "Epoch 12/30\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.0611 - accuracy: 0.9811 - val_loss: 0.0381 - val_accuracy: 0.9893\n",
      "Epoch 13/30\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 0.0563 - accuracy: 0.9824 - val_loss: 0.0380 - val_accuracy: 0.9893\n",
      "Epoch 14/30\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 0.0569 - accuracy: 0.9821 - val_loss: 0.0372 - val_accuracy: 0.9893\n",
      "Epoch 15/30\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 0.0530 - accuracy: 0.9831 - val_loss: 0.0369 - val_accuracy: 0.9898\n",
      "Epoch 16/30\n",
      "375/375 [==============================] - 22s 57ms/step - loss: 0.0481 - accuracy: 0.9851 - val_loss: 0.0356 - val_accuracy: 0.9900\n",
      "Epoch 17/30\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 0.0530 - accuracy: 0.9831 - val_loss: 0.0407 - val_accuracy: 0.9887\n",
      "Epoch 18/30\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 0.0473 - accuracy: 0.9854 - val_loss: 0.0372 - val_accuracy: 0.9893\n",
      "Epoch 19/30\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 0.0439 - accuracy: 0.9862 - val_loss: 0.0350 - val_accuracy: 0.9901\n",
      "Epoch 20/30\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 0.0451 - accuracy: 0.9858 - val_loss: 0.0417 - val_accuracy: 0.9893\n",
      "Epoch 21/30\n",
      "375/375 [==============================] - 22s 59ms/step - loss: 0.0445 - accuracy: 0.9862 - val_loss: 0.0382 - val_accuracy: 0.9912\n",
      "Epoch 22/30\n",
      "375/375 [==============================] - 23s 60ms/step - loss: 0.0444 - accuracy: 0.9863 - val_loss: 0.0341 - val_accuracy: 0.9918\n",
      "Epoch 23/30\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 0.0426 - accuracy: 0.9861 - val_loss: 0.0463 - val_accuracy: 0.9879\n",
      "Epoch 24/30\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 0.0424 - accuracy: 0.9870 - val_loss: 0.0392 - val_accuracy: 0.9902\n",
      "Epoch 25/30\n",
      "375/375 [==============================] - 23s 60ms/step - loss: 0.0393 - accuracy: 0.9876 - val_loss: 0.0359 - val_accuracy: 0.9908\n",
      "Epoch 26/30\n",
      "375/375 [==============================] - 23s 60ms/step - loss: 0.0400 - accuracy: 0.9872 - val_loss: 0.0395 - val_accuracy: 0.9902\n",
      "Epoch 27/30\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 0.0377 - accuracy: 0.9876 - val_loss: 0.0462 - val_accuracy: 0.9883\n",
      "Epoch 28/30\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 0.0354 - accuracy: 0.9891 - val_loss: 0.0432 - val_accuracy: 0.9888\n",
      "Epoch 29/30\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 0.0348 - accuracy: 0.9886 - val_loss: 0.0372 - val_accuracy: 0.9902\n",
      "Epoch 30/30\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 0.0369 - accuracy: 0.9887 - val_loss: 0.0395 - val_accuracy: 0.9905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26aaceec520>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       980\n",
      "           1       0.99      1.00      1.00      1135\n",
      "           2       0.99      0.99      0.99      1032\n",
      "           3       0.99      0.99      0.99      1010\n",
      "           4       0.99      0.99      0.99       982\n",
      "           5       0.99      0.99      0.99       892\n",
      "           6       0.99      0.99      0.99       958\n",
      "           7       0.98      0.99      0.98      1028\n",
      "           8       0.99      0.99      0.99       974\n",
      "           9       0.99      0.98      0.99      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n",
      "[[ 976    0    2    0    0    0    1    1    0    0]\n",
      " [   0 1132    2    1    0    0    0    0    0    0]\n",
      " [   0    1 1021    1    0    0    3    6    0    0]\n",
      " [   0    0    1 1003    0    3    0    2    1    0]\n",
      " [   0    0    0    0  970    0    2    2    3    5]\n",
      " [   0    0    0    7    0  883    1    1    0    0]\n",
      " [   4    2    0    1    1    2  947    0    1    0]\n",
      " [   0    2    8    0    0    0    0 1017    1    0]\n",
      " [   2    0    0    1    1    0    0    5  961    4]\n",
      " [   0    2    0    0    4    5    0    9    0  989]]\n"
     ]
    }
   ],
   "source": [
    "y_probab = model.predict(X_test)\n",
    "y_pred = np.argmax(y_probab, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
